# Importaciones necesarias
import streamlit as st
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import warnings


# Silenciar advertencias espec칤ficas
warnings.filterwarnings("ignore", category=UserWarning, message="Found unknown categories in columns")
warnings.filterwarnings("ignore", category=FutureWarning)

from sklearn.metrics import (
    confusion_matrix, roc_auc_score, precision_score,
    recall_score, f1_score, classification_report, roc_curve,
    auc, precision_recall_curve, average_precision_score
)

# -------------------------------------------------------------------
# 1) Carga de clases personalizadas (enga침ando a joblib)
# -------------------------------------------------------------------
import utils.transformers

# Importa todas las clases necesarias desde utils.transformers
page_rank_condition = utils.transformers.page_rank_condition
ratio_digits_url_increment_condition = utils.transformers.ratio_digits_url_increment_condition
nb_subdomains_increment_condition = utils.transformers.nb_subdomains_increment_condition
length_words_raw_increment_condition = utils.transformers.length_words_raw_increment_condition
char_repeat_increment_condition = utils.transformers.char_repeat_increment_condition
shortest_word_host_increment_condition = utils.transformers.shortest_word_host_increment_condition
nb_slash_increment_condition = utils.transformers.nb_slash_increment_condition
longest_word_host_increment_condition = utils.transformers.longest_word_host_increment_condition
avg_word_host_increment_condition = utils.transformers.avg_word_host_increment_condition

# Define las clases personalizadas necesarias
class DropColumns(utils.transformers.DropColumns):
    pass

class AddWeirdColumn(utils.transformers.AddWeirdColumn):
    pass

class EncodeCategorical(utils.transformers.EncodeCategorical):
    pass

class SklearnXGBClassifier(utils.transformers.SklearnXGBClassifier):
    pass

class DataFrameStandardScaler(utils.transformers.DataFrameStandardScaler):
    pass

class RemoveBinaryDuplicates(utils.transformers.RemoveBinaryDuplicates):
    pass

# -------------------------------------------------------------------
# 2) Funci칩n avanzada de evaluaci칩n (retorna figuras)
# -------------------------------------------------------------------
from utils.functions import evaluar_modelo_completo

# Importar funciones auxiliares para la extraccion de variables

#from utils.extract_url_features import extraer_variables_url

# -------------------------------------------------------------------
# 3) Funci칩n para mostrar m칠tricas sencillas
# -------------------------------------------------------------------
def mostrar_metricas(y_true, y_pred, proba=None):
    acc = (y_pred == y_true).mean()
    prec = precision_score(y_true, y_pred, zero_division=0)
    rec = recall_score(y_true, y_pred, zero_division=0)
    f1 = f1_score(y_true, y_pred, zero_division=0)
    roc = roc_auc_score(y_true, proba) if proba is not None and len(np.unique(proba)) > 1 else None

    st.write(f"**Accuracy:** {acc:.4f}")
    st.write(f"**Precisi칩n:** {prec:.4f}")
    st.write(f"**Recall:** {rec:.4f}")
    st.write(f"**F1 Score:** {f1:.4f}")
    if roc is not None:
        st.write(f"**ROC AUC:** {roc:.4f}")
    else:
        st.write("**ROC AUC:** No disponible (proba insuficiente o `predict_proba` no soportado).")

# -------------------------------------------------------------------
# 4) Inicializar session_state si no existe
# -------------------------------------------------------------------
if "model" not in st.session_state:
    st.session_state["model"] = None
if "pipeline" not in st.session_state:
    st.session_state["pipeline"] = None
if "metadata" not in st.session_state:
    st.session_state["metadata"] = None
if "df_data" not in st.session_state:
    st.session_state["df_data"] = None
if "threshold" not in st.session_state:
    st.session_state["threshold"] = 0.5
if "analisis_avanzado" not in st.session_state:
    st.session_state["analisis_avanzado"] = False
if "figuras_analisis_avanzado" not in st.session_state:
    st.session_state["figuras_analisis_avanzado"] = []
if "y_test" not in st.session_state:
    st.session_state["y_test"] = None
if "y_proba" not in st.session_state:
    st.session_state["y_proba"] = None
if "y_pred" not in st.session_state:
    st.session_state["y_pred"] = None

# -------------------------------------------------------------------
# 5) Funciones de carga (modelo & dataset), actualizando session_state
# -------------------------------------------------------------------
def cargar_modelo_pipeline():
    """Carga modelo, pipeline y metadatos a session_state."""
    if st.session_state["model"] is None:
        try:
            st.session_state["model"] = joblib.load("Modelos/mejor_modelo.pkl")
            st.session_state["pipeline"] = joblib.load("Modelos/mejor_pipeline.pkl")
            st.session_state["metadata"] = joblib.load("Modelos/metadatos.pkl")
            st.success("Modelo, pipeline y metadatos cargados correctamente.")

            with st.expander("Ver metadatos del modelo"):
                st.json(st.session_state["metadata"])
        except Exception as e:
            st.error(f"Error al cargar modelo/pipeline: {e}")
    else:
        st.info("El modelo y pipeline ya est치n cargados en esta sesi칩n.")

def cargar_dataset(ruta):
    """Carga el parquet en df_data."""
    try:
        df = pd.read_parquet(ruta)
        st.session_state["df_data"] = df
        st.success(f"Dataset '{ruta}' cargado con 칠xito. Shape: {df.shape}")
    except Exception as e:
        st.error(f"Error al cargar dataset '{ruta}': {e}")

# -------------------------------------------------------------------
# 6) Funci칩n para descargar el dataset con predicciones
# -------------------------------------------------------------------
def descargar_predicciones(df, key):
    """Permite descargar el dataframe con las predicciones."""
    csv = df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="游닌 Descargar Predicciones como CSV",
        data=csv,
        file_name='predicciones_phishing.csv',
        mime='text/csv',
        key=key  # Asignar el key 칰nico aqu칤
    )

# -------------------------------------------------------------------
# 7) L칩gica principal
# -------------------------------------------------------------------
def main():
    st.title("Sistema de Detecci칩n de URLs Phishing :lock:")
    st.write("Bienvenido a la demo interactiva de detecci칩n de phishing. Usa la **barra lateral** para cargar el modelo y el dataset, y ajustar el umbral.")
    
    # Barra lateral:
    st.sidebar.subheader("Cargar Modelo y Pipeline")
    if st.sidebar.button("Cargar modelo/pipeline"):
        cargar_modelo_pipeline()
    
    # Mostrar estado del modelo
    if st.session_state["model"] is not None:
        st.sidebar.success("Modelo & pipeline cargados en session_state")
    else:
        st.sidebar.info("Modelo no cargado a칰n.")
    
    # Elegir dataset
    st.sidebar.subheader("Cargar Dataset")
    dataset_option = st.sidebar.selectbox("Selecciona el dataset a cargar", ["Ninguno", "Data/train.parquet", "Data/test.parquet"])
    if st.sidebar.button("Cargar Dataset"):
        if dataset_option == "Ninguno":
            st.warning("No se ha seleccionado ning칰n dataset.")
        else:
            cargar_dataset(dataset_option)
    
    # Mostrar estado del dataset
    if st.session_state["df_data"] is not None:
        st.sidebar.success("Dataset cargado en session_state")
    else:
        st.sidebar.info("Sin dataset cargado.")
    
    # Cuadro de texto para Threshold
    thr_input = st.sidebar.text_input("Umbral de decisi칩n (Threshold)", value=str(st.session_state["threshold"]))
    try:
        thr = float(thr_input)
        if thr < 0.0 or thr > 1.0:
            st.sidebar.error("El umbral debe estar entre 0 y 1.")
            thr = st.session_state["threshold"]
        else:
            st.session_state["threshold"] = thr
    except ValueError:
        st.sidebar.error("Por favor, ingresa un valor num칠rico v치lido para el umbral (entre 0 y 1).")
        thr = st.session_state["threshold"]
    
    # Crear tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["游늯 Vista de Datos", "游늵 Predicci칩n & M칠tricas", "游늳 An치lisis Avanzado", "游 Comparativa Modelos", "游댌 Predicci칩n por URL"])
    
    # ---------------- TAB 1: Vista de Datos ----------------
    with tab1:
        st.subheader("Vista Preliminar del Dataset")
        df_data = st.session_state.get("df_data", None)
        if df_data is not None:
            # Mostrar nombres de las columnas
            st.write("**Nombres de las columnas en el dataset:**")
            st.write(df_data.columns.tolist())

            # Definir las columnas a mostrar
            cols_to_display = []
            if 'status' in df_data.columns and 'url' in df_data.columns:
                cols_to_display = ['url', 'status']
            elif 'url' in df_data.columns:
                cols_to_display = ['url']

            if 'ID' in df_data.columns:
                cols_to_display = ['ID'] + cols_to_display

            # Mostrar las columnas seleccionadas si existen
            missing_cols = [col for col in cols_to_display if col not in df_data.columns]
            if not missing_cols:
                st.write("**Vista Preliminar de las Predicciones:**")
                st.dataframe(df_data[cols_to_display].head(50))  # Mostrar las primeras 50 filas
                st.write(f"**Shape:** {df_data.shape[0]:,} filas x {df_data.shape[1]} columnas.")
            else:
                st.warning(f"No se encontraron las columnas: {', '.join(missing_cols)} en el dataset.")
        else:
            st.info("Selecciona y carga un dataset en la barra lateral para ver sus datos aqu칤.")
    
    # ---------------- TAB 2: Predicci칩n & M칠tricas ----------------
    with tab2:
        st.subheader("Generar Predicciones y Ver M칠tricas B치sicas")
        model = st.session_state.get("model", None)
        pipeline = st.session_state.get("pipeline", None)
        df_data = st.session_state.get("df_data", None)
        threshold = st.session_state.get("threshold", 0.5)

        if df_data is not None and model is not None and pipeline is not None:
            # Crear una copia para el modelo, eliminando 'ID' si existe
            df_model = df_data.copy()
            if "ID" in df_model.columns:
                df_model.drop(columns=["ID"], inplace=True, errors="ignore")

            # Revisar si existe 'status'
            if "status" in df_model.columns:
                y_test = df_model["status"].values
                X_test = df_model.drop(columns=["status"], errors="ignore")
            else:
                y_test = None
                X_test = df_model

            # Transformar los datos usando el pipeline **solo las caracter칤sticas predictoras**
            try:
                X_test_proc = pipeline.transform(X_test)
                if isinstance(X_test_proc, np.ndarray):
                    try:
                        X_test_proc = pd.DataFrame(X_test_proc, columns=pipeline.get_feature_names_out())
                    except AttributeError:
                        st.warning("El pipeline no tiene m칠todo `get_feature_names_out()`. Usando nombres gen칠ricos de features.")
                        X_test_proc = pd.DataFrame(X_test_proc, columns=[f"Feature {i}" for i in range(X_test_proc.shape[1])])
                st.session_state["X_test_proc"] = X_test_proc  # Guardar para an치lisis
            except Exception as e:
                st.error(f"Error al transformar los datos: {e}")
                X_test_proc = None

            if X_test_proc is not None:
                # Predicci칩n con umbral
                try:
                    if hasattr(model, "predict_proba"):
                        y_proba = model.predict_proba(X_test_proc)[:, 1]
                        y_pred = (y_proba >= threshold).astype(int)
                    else:
                        st.warning("El modelo no soporta `predict_proba`. Se usar치 `predict` para generar las predicciones.")
                        y_pred = model.predict(X_test_proc)
                        y_proba = None
                except Exception as e:
                    st.error(f"Error en predict_proba/predict: {e}")
                    y_pred = None
                    y_proba = None

                if y_pred is not None:
                    # A침adir las predicciones al dataframe de display
                    df_display = df_data.copy()

                    # Verificar qu칠 columnas existen antes de usarlas
                    cols_to_display = []
                    for col in ['ID', 'url', 'status']:
                        if col in df_display.columns:
                            cols_to_display.append(col)

                    # A침adir 'Predicci칩n' y 'Proba' al dataframe
                    df_display["Predicci칩n"] = y_pred
                    df_display["Proba"] = y_proba if y_proba is not None else None  # Pandas maneja `None` como NaN

                    # Mostrar las predicciones
                    st.write("**Todas las Predicciones:**")
                    st.dataframe(df_display[cols_to_display + ["Predicci칩n", "Proba"]].head(50))

                    # Bot칩n para descargar todas las predicciones
                    descargar_predicciones(df_display, key='download_all_predictions')

                    # Tabla de predicciones err칩neas
                    if y_test is not None:
                        df_errors = df_display[df_display["status"] != df_display["Predicci칩n"]]
                        st.write("**Predicciones Err칩neas:**")
                        if df_errors.empty:
                            st.success("춰No hay predicciones err칩neas!")
                        else:
                            # A침adir 'Proba' si no est치 presente
                            if 'Proba' not in df_errors.columns and y_proba is not None:
                                df_errors["Proba"] = y_proba[df_errors.index]
                            st.dataframe(df_errors[cols_to_display + ["Predicci칩n", "Proba"]].head(50))  # Mostrar las primeras 50 filas
                            st.write(f"**N칰mero Total de Errores:** {df_errors.shape[0]:,}")
                            # **Bot칩n para descargar solo las predicciones err칩neas**
                            descargar_predicciones(df_errors, key='download_error_predictions')

                            st.write(f"**Umbral Actual:** {threshold:.2f}")
                            mostrar_metricas(y_test, y_pred, proba=y_proba)

                            # Matriz de confusi칩n (tama침o reducido)
                            cm = confusion_matrix(y_test, y_pred)
                            fig_cm, ax_cm = plt.subplots(figsize=(5, 4))  # Tama침o reducido
                            sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax_cm, cbar=False)
                            ax_cm.set_xlabel("Predicci칩n")
                            ax_cm.set_ylabel("Real")
                            ax_cm.set_title("Matriz de Confusi칩n")
                            fig_cm.tight_layout()
                            st.pyplot(fig_cm)

                            # Gr치fico de Barras para 'is_weird' basado en Predicci칩n
                            if 'is_weird' in X_test_proc.columns:
                                st.write("**Proporci칩n de Phishing en `is_weird`**")
                                df_weird = pd.DataFrame({
                                    'is_weird': X_test_proc['is_weird'],
                                    'Phishing': y_pred  # Usar predicciones en lugar de 'status'
                                })
                                proportion_weird = df_weird.groupby('is_weird')['Phishing'].mean().reset_index()
                                proportion_weird['Phishing'] = proportion_weird['Phishing'] * 100  # Convertir a porcentaje
                                
                                fig_weird, ax_weird = plt.subplots(figsize=(8, 6))
                                sns.barplot(data=proportion_weird, x='is_weird', y='Phishing', ax=ax_weird)
                                ax_weird.set_title("Proporci칩n de Phishing por `is_weird`")
                                ax_weird.set_xlabel("is_weird")
                                ax_weird.set_ylabel("Proporci칩n de Phishing (%)")
                                for index, row in proportion_weird.iterrows():
                                    ax_weird.text(index, row.Phishing + 0.5, f"{row.Phishing:.2f}%", color='black', ha="center")
                                fig_weird.tight_layout()
                                st.pyplot(fig_weird)
                            else:
                                st.warning("La columna `is_weird` no est치 presente en los datos transformados.")

                            # **Agregar Gr치fica de N칰mero de Fallos por Probabilidad**
                            if y_proba is not None:
                                st.write("**N칰mero de Fallos por Probabilidad de Predicci칩n**")
                                fig_failures_prob, ax_failures_prob = plt.subplots(figsize=(10, 6))
                                sns.histplot(df_errors['Proba'], bins=20, kde=False, ax=ax_failures_prob, color='red')
                                ax_failures_prob.set_title("Distribuci칩n de Probabilidades en Fallos")
                                ax_failures_prob.set_xlabel("Probabilidad de Phishing")
                                ax_failures_prob.set_ylabel("N칰mero de Fallos")
                                fig_failures_prob.tight_layout()
                                st.pyplot(fig_failures_prob)
                            else:
                                st.info("No se puede generar la gr치fica de fallos por probabilidad porque `predict_proba` no est치 disponible.")
                    else:
                        st.info("El dataset no contiene la columna 'status'. Se muestran solo predicciones.")
        else:
            st.info("Debes cargar un dataset y haber cargado el modelo/pipeline para ver m칠tricas.")
    
    # ---------------- TAB 3: An치lisis Avanzado ----------------
    with tab3:
        st.subheader("An치lisis Avanzado del Modelo (Errores y Fortalezas)")
        model = st.session_state.get("model", None)
        pipeline = st.session_state.get("pipeline", None)
        df_data = st.session_state.get("df_data", None)
        threshold = st.session_state.get("threshold", 0.5)

        if df_data is not None and model is not None and pipeline is not None:
            if "status" not in df_data.columns:
                st.warning("El dataset no contiene la columna 'status'. No se puede realizar el an치lisis avanzado.")
            else:
                # Crear una copia para el an치lisis, eliminando 'ID' si existe
                df_model_analysis = df_data.copy()
                if "ID" in df_model_analysis.columns:
                    df_model_analysis.drop(columns=["ID"], inplace=True, errors="ignore")

                # Separar caracter칤sticas y variable objetivo
                y_test = df_model_analysis["status"].values
                X_test = df_model_analysis.drop(columns=["status"], errors="ignore")

                # Transformar solo las caracter칤sticas predictoras
                try:
                    X_test_proc = pipeline.transform(X_test)
                    if isinstance(X_test_proc, np.ndarray):
                        try:
                            X_test_proc = pd.DataFrame(X_test_proc, columns=pipeline.get_feature_names_out())
                        except AttributeError:
                            st.warning("El pipeline no tiene m칠todo `get_feature_names_out()`. Usando nombres gen칠ricos de features.")
                            X_test_proc = pd.DataFrame(X_test_proc, columns=[f"Feature {i}" for i in range(X_test_proc.shape[1])])
                    st.session_state["X_test_proc"] = X_test_proc  # Guardar para an치lisis
                except Exception as e:
                    st.error(f"Error al transformar los datos: {e}")
                    X_test_proc = None

                if X_test_proc is not None:
                    # Predicciones
                    try:
                        if hasattr(model, "predict_proba"):
                            y_proba = model.predict_proba(X_test_proc)[:, 1]
                            y_pred = (y_proba >= threshold).astype(int)
                        else:
                            st.warning("El modelo no soporta `predict_proba`. Se usar치 `predict` para generar las predicciones.")
                            y_pred = model.predict(X_test_proc)
                            y_proba = None
                    except Exception as e:
                        st.error(f"Error en predict_proba/predict: {e}")
                        y_pred = None
                        y_proba = None

                    if y_pred is not None:
                        # Llamar a la funci칩n de evaluaci칩n completa
                        figs = evaluar_modelo_completo(model, X_test_proc, y_test, model_name="Phishing Demo")
                        st.session_state["figuras_analisis_avanzado"] = figs
                        st.session_state["y_test"] = y_test
                        st.session_state["y_proba"] = y_proba
                        st.session_state["y_pred"] = y_pred
                        st.session_state["analisis_avanzado"] = True
                        st.success("An치lisis avanzado calculado y almacenado.")

                        # Mostrar los gr치ficos almacenados
                        if st.session_state["analisis_avanzado"]:
                            figs = st.session_state.get("figuras_analisis_avanzado", [])
                            y_test = st.session_state.get("y_test", None)
                            y_proba = st.session_state.get("y_proba", None)
                            y_pred = st.session_state.get("y_pred", None)

                            if figs:
                                for i, fig in enumerate(figs, start=1):
                                    st.write(f"**Gr치fico {i}**:")
                                    st.pyplot(fig)

                                # A침adir an치lisis adicional: URLs donde el modelo falla
                                st.markdown("---")
                                st.subheader("An치lisis de URLs donde el Modelo Falla")

                                # Crear dataframe con predicciones
                                df_analysis = df_data.copy()
                                if "ID" in df_analysis.columns:
                                    df_analysis = df_analysis[['ID', 'url', 'status']].copy()
                                else:
                                    df_analysis = df_analysis[['url', 'status']].copy()

                                # A침adir las predicciones y probabilidades
                                df_analysis["Predicci칩n"] = y_pred
                                if y_proba is not None:
                                    df_analysis["Proba"] = y_proba
                                else:
                                    df_analysis["Proba"] = np.nan
                                df_analysis["Correcto"] = df_analysis["status"] == df_analysis["Predicci칩n"]

                                # Seleccionar caracter칤sticas num칠ricas y categ칩ricas disponibles
                                available_features = X_test.select_dtypes(include=[np.number, 'category']).columns.tolist()
                                # A침adir 'is_weird' si est치 disponible
                                if 'is_weird' in X_test_proc.columns and 'is_weird' not in available_features:
                                    available_features.append('is_weird')

                                if not available_features:
                                    st.warning("No hay caracter칤sticas num칠ricas o categ칩ricas disponibles para el an치lisis.")
                                else:
                                    selected_feature = st.selectbox("Selecciona una caracter칤stica para analizar", available_features)

                                    if selected_feature:
                                        # A침adir la caracter칤stica al dataframe de an치lisis
                                        if selected_feature in df_data.columns:
                                            df_analysis[selected_feature] = df_data[selected_feature]
                                        elif selected_feature in X_test_proc.columns:
                                            df_analysis[selected_feature] = X_test_proc[selected_feature]
                                        else:
                                            st.warning(f"La caracter칤stica seleccionada '{selected_feature}' no est치 disponible.")
                                            df_analysis[selected_feature] = np.nan

                                        # Determinar si es num칠rica o categ칩rica
                                        if pd.api.types.is_numeric_dtype(df_analysis[selected_feature]):
                                            unique_values = df_analysis[selected_feature].nunique()
                                            if unique_values > 10:
                                                # Convertir a float32 para evitar el error
                                                df_analysis[selected_feature] = df_analysis[selected_feature].astype(np.float32)
                                                
                                                # Binarizar la variable en categor칤as (por ejemplo, usando cuantiles)
                                                num_bins = st.slider("Selecciona el n칰mero de bins para la caracter칤stica continua", min_value=2, max_value=10, value=5)
                                                try:
                                                    df_analysis[f"{selected_feature}_binned"] = pd.qcut(df_analysis[selected_feature], q=num_bins, duplicates='drop')
                                                except ValueError:
                                                    st.warning("No se pudo binarizar la caracter칤stica seleccionada. Intentando con menos bins.")
                                                    df_analysis[f"{selected_feature}_binned"] = pd.qcut(df_analysis[selected_feature], q=num_bins-1, duplicates='drop')
                                                feature_to_plot = f"{selected_feature}_binned"
                                            else:
                                                # Usar la caracter칤stica directamente si tiene pocos valores 칰nicos
                                                feature_to_plot = selected_feature
                                        else:
                                            feature_to_plot = selected_feature

                                        # Calcular las proporciones de aciertos y errores por categor칤a
                                        df_grouped = df_analysis.groupby(feature_to_plot)["Correcto"].value_counts(normalize=True).unstack(fill_value=0)

                                        # Renombrar las columnas para claridad
                                        if 'False' in df_grouped.columns and 'True' in df_grouped.columns:
                                            df_grouped.columns = ["Errores", "Aciertos"]
                                        elif 'True' in df_grouped.columns:
                                            df_grouped.columns = ["Aciertos"]
                                        elif 'False' in df_grouped.columns:
                                            df_grouped.columns = ["Errores"]

                                        # Gr치fico de barras apiladas con etiquetas de proporci칩n
                                        fig_grouped, ax_grouped = plt.subplots(figsize=(12, 6))
                                        df_grouped.plot(kind='bar', stacked=True, color=['red', 'green'], ax=ax_grouped)

                                        ax_grouped.set_title(f"Proporci칩n de Aciertos y Errores por '{feature_to_plot}'")
                                        ax_grouped.set_xlabel(feature_to_plot)
                                        ax_grouped.set_ylabel("Proporci칩n")
                                        ax_grouped.legend(["Errores", "Aciertos"], loc='upper right')

                                        # A침adir etiquetas con las proporciones
                                        for container in ax_grouped.containers:
                                            ax_grouped.bar_label(container, fmt="%.2f", label_type='center')

                                        fig_grouped.tight_layout()
                                        st.pyplot(fig_grouped)

                                        st.markdown("""
                                        **Interpretaci칩n:**
                                        - **Aciertos (Verde):** Proporci칩n de URLs clasificadas correctamente en cada categor칤a de la caracter칤stica seleccionada.
                                        - **Errores (Rojo):** Proporci칩n de URLs clasificadas incorrectamente en cada categor칤a de la caracter칤stica seleccionada.
                                        - Observa las diferencias en las proporciones para identificar patrones que podr칤an ayudar a mejorar el modelo.
                                        """)

                                        # Mostrar proporciones globales
                                        st.write(f"**Proporci칩n de Aciertos:** {np.mean(y_test == y_pred) * 100:.2f}%")
                                        st.write(f"**Proporci칩n de Errores:** {100 - np.mean(y_test == y_pred) * 100:.2f}%")
        else:
            st.info("Debes cargar un dataset y haber cargado el modelo/pipeline para realizar el an치lisis avanzado.")

    # ---------------- TAB 4: Comparativa de Modelos ----------------
    with tab4:
        st.subheader("Comparaci칩n de Varios Modelos")
        st.write("Sube un CSV con m칠tricas de distintos modelos para compararlos.")
        comp_file = st.file_uploader("Subir CSV de Comparativa", key="comp", type=["csv"])
        if comp_file is not None:
            try:
                df_comp = pd.read_csv(comp_file)
                st.dataframe(df_comp)

                # Mostrar informaci칩n de las columnas
                st.markdown("**Descripci칩n de las Columnas:**")
                st.write(df_comp.dtypes)

                # Verificar columnas necesarias
                required_cols = {"Modelo", "Prueba", "F1-Validation"}
                if required_cols.issubset(df_comp.columns):
                    # Mostrar valores 칰nicos de "Prueba" para clarificaci칩n
                    st.markdown("**Valores 칔nicos de 'Prueba':**")
                    st.write(df_comp["Prueba"].unique())

                    # Gr치fico de barras con etiquetas para F1-Validation
                    fig_comp, ax_comp = plt.subplots(figsize=(14, 8))
                    sns.barplot(data=df_comp, x="Modelo", y="F1-Validation", hue="Prueba", ax=ax_comp)
                    ax_comp.set_title("Comparativa de F1-Validation")
                    ax_comp.set_xlabel("Modelo")
                    ax_comp.set_ylabel("F1-Validation")

                    # A침adir etiquetas con los valores
                    for container in ax_comp.containers:
                        ax_comp.bar_label(container, fmt="%.3f", label_type='edge')

                    # Ajustar la leyenda para que no tape el gr치fico
                    ax_comp.legend(title="Prueba", loc='upper left', bbox_to_anchor=(1.0, 1))
                    fig_comp.tight_layout()
                    st.pyplot(fig_comp)

                    # Gr치fico adicional: Scatter plot de F1-Validation vs F1-Test si existe
                    if {"F1-Test"}.issubset(df_comp.columns):
                        fig_scatter, ax_scatter = plt.subplots(figsize=(10, 8))
                        sns.scatterplot(data=df_comp, x="F1-Validation", y="F1-Test", hue="Modelo", style="Prueba", s=100, ax=ax_scatter)
                        ax_scatter.set_title("F1-Validation vs F1-Test por Modelo y Prueba")
                        ax_scatter.set_xlabel("F1-Validation")
                        ax_scatter.set_ylabel("F1-Test")

                        # A침adir anotaciones para mejor claridad
                        for i in range(df_comp.shape[0]):
                            ax_scatter.text(df_comp["F1-Validation"].iloc[i]+0.001, df_comp["F1-Test"].iloc[i]+0.001,
                                            df_comp["Modelo"].iloc[i], horizontalalignment='left', size='small', color='black', weight='semibold')

                        ax_scatter.legend(title="Prueba", loc='upper left', bbox_to_anchor=(1.0, 1))
                        fig_scatter.tight_layout()
                        st.pyplot(fig_scatter)

                    # Gr치fico adicional 1: Overfitting (Comparaci칩n de m칠tricas entre Train, Validation y Test)
                    if {"F1-Train", "F1-Validation", "F1-Test"}.issubset(df_comp.columns):
                        fig_overfit, ax_overfit = plt.subplots(figsize=(14, 8))
                        df_overfit = df_comp.melt(id_vars=["Modelo", "Prueba"], value_vars=["F1-Train", "F1-Validation", "F1-Test"], var_name="Conjunto", value_name="F1-Score")
                        sns.barplot(data=df_overfit, x="Modelo", y="F1-Score", hue="Conjunto", ax=ax_overfit)
                        ax_overfit.set_title("Comparaci칩n de F1-Score entre Train, Validation y Test")
                        ax_overfit.set_xlabel("Modelo")
                        ax_overfit.set_ylabel("F1-Score")

                        # A침adir etiquetas con los valores
                        for container in ax_overfit.containers:
                            ax_overfit.bar_label(container, fmt="%.3f", label_type='edge')

                        ax_overfit.legend(title="Conjunto", loc='upper left', bbox_to_anchor=(1.0, 1))
                        fig_overfit.tight_layout()
                        st.pyplot(fig_overfit)

                    # Gr치fico adicional 2: Intervalos de Confianza (Boxplot de m칠tricas)
                    metrics = ["Accuracy", "Precision", "Recall", "F1-Validation", "F1-Test", "F1-Train"]
                    available_metrics = [metric for metric in metrics if metric in df_comp.columns]
                    if available_metrics:
                        fig_confidence, ax_confidence = plt.subplots(figsize=(14, 8))
                        df_melt = df_comp.melt(id_vars=["Modelo", "Prueba"], value_vars=available_metrics, var_name="M칠trica", value_name="Valor")
                        sns.boxplot(data=df_melt, x="Modelo", y="Valor", hue="M칠trica", ax=ax_confidence)
                        ax_confidence.set_title("Intervalos de Confianza de las M칠tricas por Modelo")
                        ax_confidence.set_xlabel("Modelo")
                        ax_confidence.set_ylabel("Valor de la M칠trica")

                        # A침adir etiquetas con los valores
                        ax_confidence.legend(title="M칠trica", loc='upper left', bbox_to_anchor=(1.0, 1))
                        fig_confidence.tight_layout()
                        st.pyplot(fig_confidence)

                    # Gr치fico adicional 3: Diferencia entre Test y Train
                    if {"F1-Train", "F1-Test"}.issubset(df_comp.columns):
                        df_overfit_diff = df_comp.copy()
                        df_overfit_diff["Diferencia"] = abs(df_overfit_diff["F1-Test"] - df_overfit_diff["F1-Train"])


                        fig_diff, ax_diff = plt.subplots(figsize=(14, 8))
                        sns.barplot(data=df_overfit_diff, x="Modelo", y="Diferencia", hue="Prueba", ax=ax_diff)
                        ax_diff.set_title("Diferencia de F1-Score entre Test y Train")
                        ax_diff.set_xlabel("Modelo")
                        ax_diff.set_ylabel("Diferencia de F1-Score")

                        # A침adir etiquetas con los valores
                        for container in ax_diff.containers:
                            ax_diff.bar_label(container, fmt="%.3f", label_type='edge')

                        ax_diff.legend(title="Prueba", loc='upper left', bbox_to_anchor=(1.0, 1))
                        fig_diff.tight_layout()
                        st.pyplot(fig_diff)

                else:
                    st.warning(f"El CSV debe contener al menos las columnas: {', '.join(required_cols)}")
            except Exception as e:
                st.error(f"Error al procesar el archivo CSV: {e}")

    # ---------------- TAB 5: Check URL ----------------
    with tab5:
        # Pesta침a de predicci칩n por URL
        st.subheader("PROXIMAMENTE FUNCIONAL")
        '''input_url = st.text_input("URL", placeholder="https://ejemplo.com")
        
        if st.button("Predecir"):
            if input_url:
                try:
                    # Extraer variables de la URL
                    df_url = extraer_variables_url(input_url)

                    # Verificar si el pipeline y el modelo est치n cargados
                    model = st.session_state.get("model", None)
                    pipeline = st.session_state.get("pipeline", None)

                    if pipeline is not None and model is not None:
                        # Procesar con el pipeline
                        df_processed = pipeline.transform(df_url)

                        # Realizar predicci칩n
                        if hasattr(model, "predict_proba"):
                            proba = model.predict_proba(df_processed)[:, 1][0]
                            prediccion = "Phishing" if proba > 0.5 else "Leg칤tima"
                            st.success(f"La URL es: **{prediccion}**")
                            st.write(f"**Probabilidad de Phishing:** {proba:.2f}")
                        else:
                            st.error("El modelo no soporta `predict_proba`.")
                    else:
                        st.error("Modelo o pipeline no cargados. Por favor, c치rgalos en la barra lateral.")
                except Exception as e:
                    st.error(f"Error al procesar la URL: {e}")
            else:
                st.warning("Por favor, introduce una URL v치lida.")'''

if __name__ == "__main__":
    main()
